{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing ADAS data with pandas for Argon with $\\lambda = 750 nm$\n",
    "\n",
    "Link to the original notebook:\n",
    "https://nbviewer.jupyter.org/gist/anonymous/40a8f1b3b5e58a63e6c67e703f7c50c7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = '../data/adas/ar_750.dat'\n",
    "# open the file, read the number of lines and save\n",
    "# the line where densities are stored (line 2)\n",
    "with open(file_path) as file:\n",
    "    for line_number, line_text in enumerate(file):\n",
    "        if line_number == 1:\n",
    "            density_index = line_text\n",
    "num_lines = line_number + 1\n",
    "\n",
    "# read two dataframes as suggested on stackoverflow\n",
    "df2 = pd.read_csv(file_path, delim_whitespace=True,\n",
    "                  skiprows=filter(lambda x: x%2==0, range(3, num_lines)),\n",
    "                  header=3)\n",
    "df3 = pd.read_csv(file_path, delim_whitespace=True,\n",
    "                  skiprows=filter(lambda x: x%2==1, range(2, num_lines)),\n",
    "                  header=2)\n",
    "\n",
    "# concat the dataframes in order to have a single dataframe\n",
    "df = pd.concat([df2, df3], axis=1)\n",
    "# add the index values to the dataframes (i.e the densities)\n",
    "df.index = density_index.strip().split(' ')\n",
    "# add the densities as a column\n",
    "df['n_e'] = df.index.values\n",
    "# reorder the dataframe for data analysis: we want three columns,\n",
    "# n_e, T_e, X_e\n",
    "df_melt = pd.melt(df, id_vars='n_e', var_name='T_e', value_name='X_e')\n",
    "# convert all the values in the column to numbers instead of string\n",
    "df_melt = df_melt.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interpolation:\n",
    "# first, we can see that both p.e.c and n_e have very\n",
    "# high ranges. So for a simpler interpolation we can\n",
    "# use their logarithms\n",
    "# log_n = np.log10(df_melt.n_e)\n",
    "# log_pec = np.log10(df_melt.n_e)\n",
    "df_melt[['n_e', 'X_e']] = df_melt[['n_e', 'X_e']].apply(np.log10)\n",
    "\n",
    "# we want the following relation:\n",
    "# T = T(n, pec)\n",
    "# let's see if scipy.interpolate.griddata can do the work\n",
    "known_points = df_melt[['n_e', 'X_e']]\n",
    "random_points = np.array([np.linspace(10, 16, 1000), np.linspace(-12, -74, 1000)]).T\n",
    "grid = interpolate.griddata(known_points, df_melt.T_e, random_points, method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f64c2ae3128>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot interpolation data\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "n_e, pec = np.meshgrid(random_points[:,0], random_points[:,1])\n",
    "ax.plot_surface(n_e, pec, grid)\n",
    "ax.set_zlabel('T (eV)')\n",
    "ax.set_xlabel('Log n ($m^{-3}$)')\n",
    "ax.set_ylabel('Log X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the functions for functions.py\n",
    "def read_adas_file(file_path, element='ar'):\n",
    "    '''\n",
    "    This function reads the adas .dat file and \n",
    "    returns a pandas dataframe with three cols:\n",
    "    n_e, T_e, X\n",
    "    '''\n",
    "    # open the file, read the number of lines and save\n",
    "    # the line where densities are stored (line 2)\n",
    "    with open(file_path) as file:\n",
    "        for line_number, line_text in enumerate(file):\n",
    "            if line_number == 1:\n",
    "                density_index = line_text\n",
    "    num_lines = line_number + 1\n",
    "\n",
    "    if (element == 'ar'):\n",
    "        # read two dataframes as suggested on stackoverflow\n",
    "        df2 = pd.read_csv(file_path, delim_whitespace=True,\n",
    "                          skiprows=filter(lambda x: x%2==0, range(3, num_lines)),\n",
    "                          header=3)\n",
    "        df3 = pd.read_csv(file_path, delim_whitespace=True,\n",
    "                          skiprows=filter(lambda x: x%2==1, range(2, num_lines)),\n",
    "                          header=2)\n",
    "\n",
    "    # concat the dataframes in order to have a single dataframe\n",
    "    df = pd.concat([df2, df3], axis=1)\n",
    "    # add the index values to the dataframes (i.e the densities)\n",
    "    df.index = density_index.strip().split(' ')\n",
    "    # add the densities as a column\n",
    "    df['n_e'] = df.index.values\n",
    "    # reorder the dataframe for data analysis: we want three columns,\n",
    "    # n_e, T_e, X_e\n",
    "    df_melt = pd.melt(df, id_vars='n_e', var_name='T_e', value_name='X_e')\n",
    "    # convert all the values in the column to numbers instead of string\n",
    "    df_melt = df_melt.apply(pd.to_numeric)\n",
    "    \n",
    "    return df_melt\n",
    "\n",
    "def interpolate_dataframe(df, points):\n",
    "    '''\n",
    "    This function takes a pandas dataframe with three cols:\n",
    "    n_e, T_e, X and a points array with shape (n, 2).\n",
    "    It returns an array with dimension (n,) with the \n",
    "    interpolated temperature values. For faster and\n",
    "    simpler interpolation it converts both the n_e and T_e\n",
    "    into log10 arrays.\n",
    "    '''\n",
    "    # interpolation:\n",
    "    # first, we can see that both p.e.c and n_e have very\n",
    "    # high range. So for a simpler interpolation we can\n",
    "    # use their logarithms\n",
    "    # log_n = np.log10(df_melt.n_e)\n",
    "    # log_pec = np.log10(df_melt.n_e)\n",
    "    df_melt[['n_e', 'X_e']] = df_melt[['n_e', 'X_e']].apply(np.log10)\n",
    "\n",
    "    # we want the following relation:\n",
    "    # T = T(n, pec)\n",
    "    # let's see if scipy.interpolate.griddata can do the work\n",
    "    known_points = df_melt[['n_e', 'X_e']]\n",
    "    # random_points = np.array([np.linspace(10, 16, 1000), np.linspace(-12, -74, 1000)]).T\n",
    "    grid = interpolate.griddata(known_points, df_melt.T_e, points, method='cubic')\n",
    "    \n",
    "    return grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
